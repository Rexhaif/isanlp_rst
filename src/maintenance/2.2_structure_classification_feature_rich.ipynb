{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary structure classification used in tree building: Step 2. Feature-rich approach\n",
    "\n",
    "Train models, save the best one.\n",
    "\n",
    "Output:\n",
    " - ``models/structure_predictor_baseline/*``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from utils.file_reading import read_edus, read_gold, read_negative, read_annotation\n",
    "from utils.prepare_sequence import _prepare_sequence\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "random_state = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = 'models/structure_predictor_baseline'\n",
    "! mkdir $model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IN_PATH = 'data_structure'\n",
    "\n",
    "train_samples = pd.read_pickle(os.path.join(IN_PATH, 'train_samples.pkl'))\n",
    "dev_samples = pd.read_pickle(os.path.join(IN_PATH, 'dev_samples.pkl'))\n",
    "test_samples = pd.read_pickle(os.path.join(IN_PATH, 'test_samples.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['snippet_x', 'snippet_y', 'category_id', \n",
    "                'snippet_x_tmp', 'snippet_y_tmp', \n",
    "                'filename', 'order', 'postags_x', 'postags_y',\n",
    "                'is_broken', 'tokens_x', 'tokens_y', 'level_0']\n",
    "\n",
    "y_train, X_train = train_samples['relation'].to_frame(), train_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "y_dev, X_dev = dev_samples['relation'].to_frame(), dev_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])\n",
    "y_test, X_test = test_samples['relation'].to_frame(), test_samples.drop('relation', axis=1).drop(\n",
    "    columns=drop_columns + ['category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "constants = [c for c in X_train.columns if len(set(X_train[c])) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(columns=constants)\n",
    "X_dev = X_dev.drop(columns=constants)\n",
    "X_test = X_test.drop(columns=constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "std_scaler = MinMaxScaler().fit(X_train.values)\n",
    "\n",
    "X_train = pd.DataFrame(std_scaler.transform(X_train.values), index=X_train.index, columns=X_train.columns)\n",
    "X_dev = pd.DataFrame(std_scaler.transform(X_dev.values), index=X_dev.index, columns=X_dev.columns)\n",
    "X_test = pd.DataFrame(std_scaler.transform(X_test.values), index=X_test.index, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', C=0.0005, n_jobs=4, class_weight='balanced', random_state=random_state)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "print('pr:', metrics.precision_score(y_test, predicted))\n",
    "print('re:', metrics.recall_score(y_test, predicted))\n",
    "print('f1:', metrics.f1_score(y_test, predicted))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(random_state=random_state, C=0.01, class_weight='balanced')\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "model = svc\n",
    "predicted = model.predict(X_dev)\n",
    "print('f1: %.2f'%(metrics.f1_score(y_dev, predicted)*100.))\n",
    "print('pr: %.2f'%(metrics.precision_score(y_dev, predicted)*100.))\n",
    "print('re: %.2f'%(metrics.recall_score(y_dev, predicted)*100.))\n",
    "print()\n",
    "print(metrics.classification_report(y_dev, predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X_test)\n",
    "print('f1: %.2f'%(metrics.f1_score(y_test, predicted)*100.))\n",
    "print('pr: %.2f'%(metrics.precision_score(y_test, predicted)*100.))\n",
    "print('re: %.2f'%(metrics.recall_score(y_test, predicted)*100.))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, predicted, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.labels = [\"0\", \"1\"]\n",
    "pickle.dump(svc, open(os.path.join(model_path, 'model.pkl'), 'wb'))\n",
    "pickle.dump(std_scaler, open(os.path.join(model_path, 'scaler.pkl'), 'wb'))\n",
    "pickle.dump(constants+drop_columns, open(os.path.join(model_path, 'drop_columns.pkl'), 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
